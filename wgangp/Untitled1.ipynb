{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(fs, fm, init_sigma, init_mean, alpha, noise_dim):\n",
    "    \"\"\" \n",
    "    fs = (20,1) dimensione filtro\n",
    "    fm = 4 numero di filtri\n",
    "    init_sigma = 0.2 varianza distribuzione normale per l'inizializzazione dei pesi del  modello\n",
    "    init_mean = 0.03 media distribuzione normale per l'inizializzazione dei pesi del  modello\n",
    "    alpha = 0.3 pendenza parte negativa del leaky relu\n",
    "    \"\"\"\n",
    "    reg = l2(l=0.001)\n",
    "    generator = Sequential()\n",
    "    # Starting size\n",
    "    generator.add(Dense(25*fm, kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma), input_dim=noise_dim))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    #20x1\n",
    "    generator.add(Reshape((25, 1, fm)))\n",
    "    #5x4\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    #generator.add(LSTM(20))\n",
    "    generator.add(Conv2DTranspose(fm//2, fs, strides=(5,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    #50x4\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2DTranspose(fm//4, fs, strides=(2,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2DTranspose(fm//8, fs, strides=(2,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    #50x4\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2DTranspose(fm//16, fs, strides=(2,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(Conv2DTranspose(1, fs, strides=(2,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    generator.add(Activation(\"tanh\"))\n",
    "    \n",
    "    # convolutional layer with a single filter that could perform the denoise of the signal.\n",
    "    #generator.add(Conv2DTranspose(1, (10,1), padding='same', kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "\n",
    "    generator.add(Reshape((2000, 1)))\n",
    "    generator.summary()\n",
    "\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import *\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def build_generator(fs, fm, init_sigma, init_mean, alpha, noise_dim):\n",
    "    \"\"\" \n",
    "    fs = (20,1) dimensione filtro\n",
    "    fm = 4 numero di filtri\n",
    "    init_sigma = 0.2 varianza distribuzione normale per l'inizializzazione dei pesi del  modello\n",
    "    init_mean = 0.03 media distribuzione normale per l'inizializzazione dei pesi del  modello\n",
    "    alpha = 0.3 pendenza parte negativa del leaky relu\n",
    "    \"\"\"\n",
    "    reg = l2(l=0.001)\n",
    "    generator = Sequential()\n",
    "    # Starting size\n",
    "    generator.add(Dense(25*fm, kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma), input_dim=noise_dim))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    #20x1\n",
    "    generator.add(Reshape((2000,1)))\n",
    "    #5x4\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(LSTM(20))\n",
    "    #generator.add(Conv2DTranspose(fm//2, fs, strides=(5,1), padding='same', kernel_regularizer=reg, bias_regularizer=reg, kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "    #generator.add(ELU())\n",
    "    generator.add(ReLU())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    generator.add(Activation(\"tanh\"))\n",
    "    \n",
    "    # convolutional layer with a single filter that could perform the denoise of the signal.\n",
    "    #generator.add(Conv2DTranspose(1, (10,1), padding='same', kernel_initializer=RandomNormal(init_mean, init_sigma)))\n",
    "\n",
    "    generator.add(Reshape((2000, 1)))\n",
    "    generator.summary()\n",
    "\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 3200)              323200    \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 25, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 25, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 125, 1, 64)        819264    \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 125, 1, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 125, 1, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 250, 1, 32)        204832    \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 250, 1, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 250, 1, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 500, 1, 16)        51216     \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 500, 1, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 500, 1, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 1000, 1, 8)        12808     \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 1000, 1, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 1000, 1, 8)        32        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 2000, 1, 1)        801       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2000, 1, 1)        0         \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 2000, 1)           0         \n",
      "=================================================================\n",
      "Total params: 1,413,113\n",
      "Trainable params: 1,412,617\n",
      "Non-trainable params: 496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen = build_generator(fs=(100,1),\n",
    "        fm=128,\n",
    "        init_sigma = 0.003,\n",
    "        init_mean = 0.0,\n",
    "        alpha = 0.2,\n",
    "        noise_dim=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
